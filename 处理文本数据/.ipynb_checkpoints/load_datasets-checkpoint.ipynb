{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b552d-39fc-4c38-96a7-e24046526000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e9df7-6b8a-4200-b94a-bdd7dc16310d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_train = load_files(\"./aclImdb_v1/aclImdb/train/\")\n",
    "# load_files返回一个Bunch对象，其中包含训练文本和训练标签\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))\n",
    "print(\"text_train[0]:\\n{}\".format(text_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14918168-fd9f-47c8-99c6-7cd9397c5e9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 对于 v1.0 版数据，其训练集大小是 75 000，而不是 25 000，因为其中还包含 50 000 个用于无监督学习的无标签文档。在进行后续操作之前，建议先将这 50 000 个无标签文档从训练集中剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ea0de-58e4-414b-99b9-65522e06e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78443f23-01c3-46e2-8547-237ab8065034",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef7d91-7125-472c-baa4-81516cbac2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Samples per class (training): {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9884bfc-ac1a-4e82-9b05-57bcb93e1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"./aclImdb_v1/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"Number of documents in test data: {}\".format(len(text_test)))\n",
    "print(\"Samples per class (test): {}\".format(np.bincount(y_test)))\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92058aa1-9a8b-41d1-aafd-449950f8ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952a719-5834-435d-abf0-130ba69bbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b698de-0ccc-45ad-b9d1-2659464d5adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))\n",
    "\n",
    "\n",
    "# logicreg = LogisticRegression(max_iter=4000)\n",
    "# logicreg.fit(X_train, y_train)\n",
    "# 保存模型,我们想要导入的是模型本身，所以用“wb”方式写入，即是二进制方式,DT是模型名字\n",
    "# pickle.dump(logicreg, open(\"textlogicreg.dat\",\"wb\"))   # open(\"dtr.dat\",\"wb\")意思是打开叫\"dtr.dat\"的文件,操作方式是写入二进制数据\n",
    "\n",
    "# 加载模型 \n",
    "# loaded_model = pickle.load(open(\"textlogicreg.dat\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54f7a0-debc-4910-ac5c-da34d0fe8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0837568-c411-4dce-91e2-1d556287e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb69997-28da-4f6a-9752-3e8b0385a3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=4000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9c432-bc14-4741-a52d-d362b2f6060d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
